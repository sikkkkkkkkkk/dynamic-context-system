#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì™¸ë¶€ ë°ì´í„° ì—°ë™ ì‹œìŠ¤í…œ - Dynamic Context Builder
GitHub Actionsë¡œ ìë™í™”ë˜ëŠ” íŠ¸ë Œë“œ ë°ì´í„° ìˆ˜ì§‘ ë° ì»¨í…ìŠ¤íŠ¸ ìƒì„±
"""

import os
import json
import time
import datetime as dt
import requests
import feedparser
from urllib.parse import urlencode
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# í™˜ê²½ë³€ìˆ˜
X_BEARER = os.getenv("X_BEARER")
YOUTUBE_API_KEY = os.getenv("YOUTUBE_API_KEY")

# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
NOW = dt.datetime.utcnow().replace(microsecond=0).isoformat() + "Z"

def score_item(freq=1, growth=0.0, trust=0.7, aeo_weight=1.0):
    """ê°„ë‹¨ ê°€ì¤‘í•© ì ìˆ˜ ê³„ì‚°"""
    return round((freq * 0.4 + growth * 0.4 + trust * 0.2) * aeo_weight, 3)

def clean_text(text):
    """í…ìŠ¤íŠ¸ ì •ì œ"""
    return " ".join((text or "").split())[:300]

def safe_request(url, headers=None, params=None, timeout=30):
    """ì•ˆì „í•œ HTTP ìš”ì²­"""
    try:
        response = requests.get(url, headers=headers, params=params, timeout=timeout)
        response.raise_for_status()
        return response
    except requests.exceptions.RequestException as e:
        logger.error(f"Request failed: {e}")
        return None

# 1) Google Trends ëŒ€ì²´ ìŠ¤í… (ì‹¤ì œë¡œëŠ” pytrends ì‚¬ìš© ê¶Œì¥)
def fetch_trends_stub(keywords):
    """íŠ¸ë Œë“œ ë°ì´í„° ìŠ¤í… - ì‹¤ì œë¡œëŠ” pytrends ì‚¬ìš©"""
    logger.info("Fetching Google Trends data (stub)")
    return [
        {"keyword": kw, "freq": 10, "growth": 0.25, "trust": 0.7, "src": "trends"} 
        for kw in keywords
    ]

# 2) X API v2 ìµœê·¼ íŠ¸ìœ— ì¹´ìš´íŠ¸
def fetch_x_counts(query, hours=24):
    """X API v2ë¥¼ í†µí•œ íŠ¸ìœ— ì¹´ìš´íŠ¸ ì¡°íšŒ"""
    if not X_BEARER:
        logger.warning("X_BEARER token not found, using dummy data")
        return {"keyword": query, "freq": 5, "growth": 0.0, "trust": 0.8, "src": "x_dummy"}
    
    logger.info(f"Fetching X data for: {query}")
    url = "https://api.twitter.com/2/tweets/counts/recent"
    headers = {"Authorization": f"Bearer {X_BEARER}"}
    params = {"query": query, "granularity": "hour"}
    
    response = safe_request(url, headers=headers, params=params)
    if response:
        data = response.json()
        total = sum([b.get("tweet_count", 0) for b in data.get("data", [])])
        return {"keyword": query, "freq": total, "growth": 0.0, "trust": 0.8, "src": "x_counts"}
    
    # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„°
    return {"keyword": query, "freq": 3, "growth": 0.0, "trust": 0.5, "src": "x_fallback"}

# 3) YouTube Data API v3 ê²€ìƒ‰ëŸ‰ ê·¼ì‚¬
def fetch_youtube_search_count(query):
    """YouTube APIë¥¼ í†µí•œ ê²€ìƒ‰ ê²°ê³¼ ì¹´ìš´íŠ¸"""
    if not YOUTUBE_API_KEY:
        logger.warning("YOUTUBE_API_KEY not found, using dummy data")
        return {"keyword": query, "freq": 8, "growth": 0.0, "trust": 0.85, "src": "youtube_dummy"}
    
    logger.info(f"Fetching YouTube data for: {query}")
    url = "https://www.googleapis.com/youtube/v3/search"
    params = {
        "part": "snippet",
        "q": query,
        "maxResults": 50,
        "key": YOUTUBE_API_KEY,
        "type": "video"
    }
    
    response = safe_request(url, params=params)
    if response:
        items = response.json().get("items", [])
        return {"keyword": query, "freq": len(items), "growth": 0.0, "trust": 0.85, "src": "youtube"}
    
    # ì‹¤íŒ¨ ì‹œ ë”ë¯¸ ë°ì´í„°
    return {"keyword": query, "freq": 5, "growth": 0.0, "trust": 0.6, "src": "youtube_fallback"}

# 4) RSS ë‰´ìŠ¤ í”¼ë“œ
def fetch_rss(url):
    """RSS í”¼ë“œì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
    logger.info(f"Fetching RSS from: {url}")
    try:
        feed = feedparser.parse(url)
        out = []
        for entry in feed.entries[:20]:
            out.append({
                "title": clean_text(entry.get("title")),
                "url": entry.get("link"),
                "src": "rss"
            })
        return out
    except Exception as e:
        logger.error(f"RSS fetch failed: {e}")
        return []

# AEO ê°€ì¤‘ì¹˜ í…Œì´ë¸”
AEO_WEIGHTS = {
    "marketing": 1.15,  # CTR ê°•í™”
    "education": 1.00,  # ì‹ ë¢°ì„± ê· í˜•
    "academic": 0.95    # ì„¤ë“ ìš”ì†Œ ìµœì†Œí™”
}

# ëª¨ë“œë³„ ê°€ì¤‘ì¹˜ ë§¤í•‘
MODE_WEIGHT = {
    "sns": "marketing",
    "sales": "marketing", 
    "blog": "marketing",
    "video": "marketing",
    "ebook": "education",
    "edu": "education",
    "public": "academic"
}

# ê¸°ë³¸ í‚¤ì›Œë“œ í’€
BASE_KEYWORDS = [
    "AI automation", "AEO", "SEO", "ChatGPT", "Claude", 
    "react", "python", "javascript", "productivity", "automation"
]

def build_context():
    """ë©”ì¸ ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ í•¨ìˆ˜"""
    logger.info("Starting context build process")
    
    # 1) ë°ì´í„° ìˆ˜ì§‘
    trends = fetch_trends_stub(BASE_KEYWORDS[:5])
    
    x_queries = ["AI automation", "SEO", "productivity"]
    xdata = [fetch_x_counts(q) for q in x_queries]
    
    yt_queries = ["AI tutorial", "SEO guide", "productivity tips"]
    ydata = [fetch_youtube_search_count(q) for q in yt_queries]
    
    # RSS ì†ŒìŠ¤ë“¤
    rss_sources = [
        "https://hnrss.org/frontpage",  # Hacker News
        "https://feeds.feedburner.com/TechCrunch"  # TechCrunch
    ]
    rss_data = []
    for rss_url in rss_sources:
        rss_data.extend(fetch_rss(rss_url))
    
    # 2) ì •ì œ ë° ìŠ¤ì½”ì–´ë§
    logger.info("Processing and scoring data")
    items = []
    all_raw_data = trends + xdata + ydata
    
    for raw in all_raw_data:
        for mode, aeo_tag in MODE_WEIGHT.items():
            weight = AEO_WEIGHTS[aeo_tag]
            items.append({
                "mode": mode,
                "keyword": raw["keyword"],
                "score": score_item(raw["freq"], raw["growth"], raw["trust"], weight),
                "source": raw["src"],
                "evidence": None
            })
    
    # ëª¨ë“œë³„ ìƒìœ„ í‚¤ì›Œë“œ ì„ ë³„
    by_mode = {}
    for item in items:
        by_mode.setdefault(item["mode"], []).append(item)
    
    top_by_mode = {
        mode: sorted(lst, key=lambda x: x["score"], reverse=True)[:5] 
        for mode, lst in by_mode.items()
    }
    
    # 3) ìš”ì•½ ë° êµ¬ì¡°í™”
    def generate_meta_description(mode):
        return f"{mode.upper()} ëª¨ë“œ ìµœì‹  íŠ¸ë Œë“œ ë°˜ì˜. í•µì‹¬ í‚¤ì›Œë“œì™€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµìœ¼ë¡œ ì¦‰ì‹œ í™œìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
    
    def generate_headings(mode):
        return [
            f"# {mode.upper()} Mode: Latest Trends",
            "## í•µì‹¬ í‚¤ì›Œë“œ",
            "## ì‹¤í–‰ ì „ëµ",
            "## FAQ"
        ]
    
    # ìµœì¢… ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    context = {
        "updated_at": NOW,
        "version": "1.0",
        "modes": []
    }
    
    for mode, keyword_list in top_by_mode.items():
        context["modes"].append({
            "mode": mode,
            "top_keywords": [
                {"keyword": item["keyword"], "score": item["score"]} 
                for item in keyword_list
            ],
            "meta_description": generate_meta_description(mode)[:158],
            "headings": generate_headings(mode),
            "faq": [
                {
                    "q": f"{mode} ëª¨ë“œì—ì„œ ì¦‰ì‹œ ì ìš©í•  ìˆ˜ ìˆëŠ” 3ê°€ì§€ëŠ”?", 
                    "a": "í•µì‹¬ í‚¤ì›Œë“œ ë°˜ì˜, ëª…í™•í•œ ê°€ì¹˜ì œì•ˆ, êµ¬ì²´ì ì¸ CTA ì„¤ì •ì…ë‹ˆë‹¤."
                },
                {
                    "q": f"{mode} ëª¨ë“œì—ì„œ í”¼í•´ì•¼ í•  ì‹¤ìˆ˜ëŠ”?", 
                    "a": "í‚¤ì›Œë“œ ë‚¨ìš©, ê²€ì¦ë˜ì§€ ì•Šì€ ì •ë³´ ì¸ìš©, ê³¼ë„í•œ í˜•ì‹ì  ìš”ì†Œ ì‚¬ìš©ì…ë‹ˆë‹¤."
                }
            ]
        })
    
    logger.info(f"Context built successfully with {len(context['modes'])} modes")
    return context, rss_data[:10]  # ì°¸ê³  ì†ŒìŠ¤ ì¼ë¶€ë§Œ ë°˜í™˜

def render_markdown(context, refs):
    """Markdown í˜•ì‹ìœ¼ë¡œ ì»¨í…ìŠ¤íŠ¸ ë Œë”ë§"""
    lines = []
    lines.append(f"<!-- Dynamic Context Block | Updated: {context['updated_at']} -->")
    lines.append(f"<!-- Version: {context['version']} -->")
    lines.append("")
    
    for mode_data in context["modes"]:
        mode = mode_data["mode"]
        lines.append(f"### [{mode.upper()}] ìµœì‹  íŠ¸ë Œë“œ í‚¤ì›Œë“œ")
        
        for keyword_data in mode_data["top_keywords"]:
            lines.append(f"- **{keyword_data['keyword']}** (ì ìˆ˜: {keyword_data['score']})")
        
        lines.append("")
        lines.append(f"**ë©”íƒ€ ì„¤ëª…**: {mode_data['meta_description']}")
        lines.append("")
        
        # í—¤ë”© êµ¬ì¡°
        for heading in mode_data["headings"]:
            lines.append(heading)
        
        lines.append("")
        lines.append("**ìì£¼ ë¬»ëŠ” ì§ˆë¬¸**")
        for faq in mode_data["faq"]:
            lines.append(f"- **Q**: {faq['q']}")
            lines.append(f"  **A**: {faq['a']}")
        
        lines.append("---")
        lines.append("")
    
    # ì°¸ê³  ì†ŒìŠ¤
    if refs:
        lines.append("### ğŸ“° ìµœì‹  ì°¸ê³  ì†ŒìŠ¤")
        for ref in refs:
            if ref.get("title") and ref.get("url"):
                lines.append(f"- [{ref['title']}]({ref['url']})")
        lines.append("")
    
    lines.append(f"*ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸: {context['updated_at']}*")
    
    return "\n".join(lines)

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        logger.info("=== Dynamic Context Builder Started ===")
        
        # ì»¨í…ìŠ¤íŠ¸ ë¹Œë“œ
        context, refs = build_context()
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs("context", exist_ok=True)
        
        # JSON íŒŒì¼ ì €ì¥
        json_path = "context/latest.json"
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(context, f, ensure_ascii=False, indent=2)
        logger.info(f"JSON saved: {json_path}")
        
        # Markdown íŒŒì¼ ì €ì¥
        md_path = "context/latest.md"
        markdown_content = render_markdown(context, refs)
        with open(md_path, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        logger.info(f"Markdown saved: {md_path}")
        
        logger.info("=== Dynamic Context Builder Completed Successfully ===")
        
    except Exception as e:
        logger.error(f"Context build failed: {e}")
        raise

if __name__ == "__main__":
    main()